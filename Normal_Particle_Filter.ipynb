{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Normal_Particle_Filter.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPWPST0yKWT5LzxpKXKK7DE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snpushpi/6.804-Computational-Cognitive-Science/blob/master/Normal_Particle_Filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJy6sEsFLgX0"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import scipy.stats"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANqwdY1fLpFU"
      },
      "source": [
        "state_set = {'A','B','C','D'}\n",
        "mu_dict = {'A':.2,'B':.4,'C':.6,'D':.8}\n",
        "sigma = 0.1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_x71oJhLs4P"
      },
      "source": [
        "def weight_based_sampling(S): #[[state,weight]]\n",
        "    states=[e[0] for e in S] \n",
        "    weights = [e[1] for e in S]\n",
        "    state =  np.random.choice(states,p=weights) #states [[][]]\n",
        "    weight = None\n",
        "    for elt in S:\n",
        "        if elt[0]==state:\n",
        "            weight = elt[1]\n",
        "    return state,weight"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1-VtTYrODRg"
      },
      "source": [
        "def weight_calculate(S):\n",
        "    weight_dict = {'A':0,'B':0,'C':0,'D':0}\n",
        "    for state,weight in S:\n",
        "        weight_dict[state]+=weight\n",
        "    return weight_dict"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_YBsma-LzEU"
      },
      "source": [
        "class Particle_Filter():\n",
        "\n",
        "    def __init__(self,particle_num,r):\n",
        "        self.n = particle_num\n",
        "        self.S = [[random.choice(tuple(state_set)),1/particle_num] for i in range(particle_num)]\n",
        "        self.r = r\n",
        "        self.prediction = None\n",
        "        self.similarity = None\n",
        "        self.weight_dict = None\n",
        "\n",
        "    def update(self,observation, human_observation):\n",
        "        '''self.S gets updated at each trial.'''\n",
        "        S_new = [] \n",
        "        eta = 0 \n",
        "        for i in range(self.n):\n",
        "            state,weight = weight_based_sampling(self.S) #a particle \n",
        "            x1 = random.uniform(0,1) \n",
        "            if x1<self.r: #change state - (1-e**(-r*k)) =>\n",
        "                new_set = state_set-{state}\n",
        "                state= random.choice(tuple(new_set))\n",
        "            new_weight = scipy.stats.norm(mu_dict[state],sigma).pdf(observation)\n",
        "            eta+= new_weight\n",
        "            S_new.append([state,new_weight])\n",
        "        S_new = [[elt[0],elt[1]/eta] for elt in S_new]\n",
        "        self.weight_dict = weight_calculate(S_new)\n",
        "        self.prediction = max(self.weight_dict, key=self.weight_dict.get)\n",
        "        self.similarity = self.weight_dict[human_observation]\n",
        "        self.S = S_new\n",
        "\n",
        "def run(particle_number,observation_list,human_inference_list,r):\n",
        "    PF = Particle_Filter(particle_number,r)\n",
        "    model_inference = []\n",
        "    for i in range(len(observation_list)):\n",
        "        PF.update(observation_list[i],human_inference_list[i])\n",
        "        model_inference.append([PF.prediction, PF.similarity])\n",
        "    return model_inference"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd0m5ZrSOmeL"
      },
      "source": [
        "def accuracy_and_similarity(human_inference_list, particle_number, observation_list, actual_list, r):\n",
        "    '''This function returns both the task accuracy and human similarity measure of the normal\n",
        "    particle filter model'''\n",
        "    model_inference_list = run(particle_number,observation_list,human_inference_list,r)\n",
        "    human_similarity_measure = 0\n",
        "    task_counter = 0\n",
        "    for i in range(len(observation_list)):\n",
        "        human_similarity_measure+=model_inference_list[i][1]\n",
        "        if actual_list[i]==model_inference_list[i][0]:\n",
        "            task_counter+=1\n",
        "    return human_similarity_measure/len(observation_list),task_counter/len(observation_list)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoW4XyyCqB9O"
      },
      "source": [
        "def data_generate(alpha,T):\n",
        "    '''Goal is generate T observations with state changing probability alpha.\n",
        "    Step 1: Set Z_0 as a random sample from state list.\n",
        "    Step 2: Repeat the following for T trials -\n",
        "          i) Z_i = Z_i-1\n",
        "          ii)Sample x randomly from [0,1]\n",
        "          iii) If x<alpha replace Z_i with random sample {A,B,C,D}/Z_i-1\n",
        "          iv)Sample stimulus y_i form a normal distribution with std sigma and mu_zi\n",
        "    '''\n",
        "    observation_list = []\n",
        "    Z = [None]*(T+1)\n",
        "    Z[0] = random.choice(tuple(state_set))\n",
        "    for i in range(1,T+1):\n",
        "        Z[i]=Z[i-1]\n",
        "        x = random.uniform(0,1)\n",
        "        if x<alpha:\n",
        "            new_set = state_set-{Z[i-1]}\n",
        "            Z[i]= random.choice(tuple(new_set))\n",
        "        observation_list.append(random.gauss(mu_dict[Z[i]],sigma))        \n",
        "    return observation_list,Z[1:]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV_clIo0uh1-"
      },
      "source": [
        "observation_list = [0.2876251534356482,\n",
        " 0.3093255562034109,\n",
        " 0.48407616095419964,\n",
        " 0.4837637156934066,\n",
        " 0.3429542790801123,\n",
        " 0.8145469658341187,\n",
        " 0.5052333561135628,\n",
        " 0.566893813089657,\n",
        " 0.5190551990406111,\n",
        " 0.6756708844580039,\n",
        " 0.5941568333778058,\n",
        " 0.6689426081101612,\n",
        " 0.08007089954529747,\n",
        " 0.24591174989381062,\n",
        " 0.13612431798914626,\n",
        " 0.16855115278807364,\n",
        " 0.02849659237553981,\n",
        " 0.2997500771551358,\n",
        " 0.3786856816409396,\n",
        " 0.17848722367921957]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0w4PMc3ul-R"
      },
      "source": [
        "actual_list = ['B',\n",
        " 'B',\n",
        " 'C',\n",
        " 'C',\n",
        " 'C',\n",
        " 'C',\n",
        " 'C',\n",
        " 'C',\n",
        " 'C',\n",
        " 'C',\n",
        " 'C',\n",
        " 'D',\n",
        " 'A',\n",
        " 'A',\n",
        " 'A',\n",
        " 'A',\n",
        " 'A',\n",
        " 'A',\n",
        " 'A',\n",
        " 'A']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNRqw-Kduq3k",
        "outputId": "c81c5c80-26d9-400f-ceb4-ccb95790b753"
      },
      "source": [
        "human_inference_list = ['B','B','C','C','C','C','C','D','D','D','D','D','A','A',\n",
        " 'A','A','A','A','B','B']\n",
        "particle_number = 100\n",
        "r = 0.2\n",
        "particle_filter_num = 10\n",
        "accuracy_and_similarity(human_inference_list, particle_number, observation_list, actual_list, r)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3940216937507329, 0.6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}